{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3v-AqBP25Gk"
   },
   "source": [
    "# Char-based text generation with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T22:10:48.370858Z",
     "start_time": "2023-05-17T22:10:47.257309Z"
    },
    "id": "Lr1W8QZo25Gr"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T22:11:07.046068Z",
     "start_time": "2023-05-17T22:10:48.372310Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NZw0dCxY25Gr",
    "outputId": "d3c6da63-30ad-454c-eec0-200f03f3e94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'а', 'о', 'л', 'е', 'р', 'к', 'н', 'х', 'и', 'т', 'ь', 'у', 'с', 'м', 'д', 'г', 'в', 'й', 'б', 'ӏ', 'ш', 'ц', 'п', 'з', 'ч', 'ъ', 'я', 'ф', 'ю', 'ж', 'э', 'c', 'i', 'ы', 't', 'u', 'і', 'n', 'r', 's', 'e', 'h', 'd', 'a', 'ё', 'l', 'm', 'o', 'щ', 'p', 'g', 'b', 'y', 'َ', '\\n', 'z', 'k', 'x', 'ِ', 'ا', 'v', 'ُ', 'ْ', 'ب', '\\u202b', '\\u202c', 'f', 'I', 'و', 'w', 'ل', 'ٌ', '²', 'à', 'j', 'q', 'ه', 'خ', 'ّ', '-', ',', 'أ', 'ك', '_', 'ٍ', 'ػ', 'ث', 'ٓ', 'ز', ']', '[', 'ë', 'ؼ', 'ر', 'ج', 'õ', '(', ')', 'ً', 'ع', 'ٞ', 'ي', 'í', 'ó', 'ؽ', 'ح', 'å', 'ٔ', 'ن', 'غ', 'ف', 'ط', 'ü', '٘', 'ٖ', 'ٕ', 'ؾ', 'ٛ', 'î', 'ى', 'ä', 'ٝ', '،', 'è', 'ٗ', 'ق', 'ð', '?', '٤', 'ت', 'é', 'ø', 'م', 'á', 'ئ', 'ê', 'ò', 'د', 'ö', 'ء', '.', 'ì', 'ة', 'â', 'ã', 'ٜ', 'ç', 'Х', '٣', 'ذ', '؟', 'ؿ', '!', 'ñ', 'ص', 'ә', 'С', 'ـ', '1', 'ظ', 'ٚ', '2', 'ú', '…', 'ٙ', 'ض', '3', 'Д', '4', 'ā', '5', 'ؤ', 'М', '٠', 'Т', 'К', 'ӑ', 'ӗ', '6', 'һ', 'ա', 'α', '٢', '8', 'آ', 'Б', 'س', '0', '7', 'А', 'ა', '9', '³', 'ҫ', 'ο', 'ý', 'Ш', 'ი', 'ј', 'æ', 'ι', 'ς', 'Г', 'π', 'Ц', 'Л', 'ش', 'ρ', 'ε', 'þ', 'ν', 'š', 'τ', 'ր', 'ٟ', 'И', 'Н', 'ī', 'ո', 'ə', 'П', '١', 'σ', 'λ', 'ː', 'ÿ', '٧', 'κ', 'В', 'μ', 'რ', 'ï', 'č', 'ო', 'β', 'ˈ', 'ѐ', 'ί', 'γ', 'ş', 'ό', 'ლ', 'ի', 'ն', 'إ', 'ე', 'ნ', 'δ', ':', 'ی', 'Ф', 'Ч', 'უ', 'ı', 'ե', 'ά', 'Я', 'ō', 'η', 'ē', 'կ', 'մ', 'მ', 'י', 'ⴰ', 'კ', 'ւ', 'ɔ', 'ɒ', 'ს', 'υ', 'ბ', 'Й', 'Р', 'ხ', 'У', 'Ж', 'З', 'ვ', 'ﷺ', 'վ', 'თ', 'ū', 'ў', 'ս', 'լ', 'դ', 'О', 'დ', 'ү', 'ר', 'Э', 'ⵜ', 'ß', 'ʿ', 'χ', 'ʼ', 'ה', 'տ', 'θ', '½', 'խ', 'յ', 'ή', 'φ', 'ө', 'ž', 'א', 'բ', 'գ', 'Е', 'έ', 'ṣ', 'ŋ', 'ԓ', 'њ', 'ω', 'թ', 'Ю', 'ו', 'ქ', 'ב', 'ք', 'є', 'გ', 'ɪ', 'ӣ', 'ת', 'ӳ', 'ң', 'І', 'ύ', 'ἀ', 'ש', 'ⴷ', 'զ', 'պ', 'ζ', 'म', 'ʃ', 'ù', 'ô', 'ɛ', 'त', 'ř', 'đ', 'қ', 'ტ', 'ƣ', 'ƶ', 'ზ', 'հ', 'შ', 'ě', 'ǻ', 'ɡ', 'כ', '«', '»', '٥', '٩', 'ʁ', 'द', 'स', 'ỳ', 'न', 'ɣ', 'ḥ', 'ŭ', 'ע', 'ⵣ', '中', 'ब', 'ס', 'չ', 'ć', 'ɵ', 'ד', 'º', 'ń', 'ჩ', 'ň', '٨', 'ܪ', 'ł', 'ġ', 'ल', 'ĕ', 'ժ', 'ʂ', 'ė', 'נ', 'ჯ', 'û', 'ງ', 'ӯ', '孔', '长', 'ʊ', 'ⴳ', 'ⴻ', 'ⵢ', 'ⵔ', 'љ', 'ğ', 'ղ', 'ˊ', 'ẋ', 'ɐ', '⅔', '⅓', 'ⵓ', 'ც', 'ῆ', 'ל', 'ק', 'ց', 'ś', 'ռ', 'ջ', 'ξ', 'ძ', 'ψ', 'ұ', 'क', 'מ', 'ყ', 'ह', 'ʰ', 'ғ', 'ວ', 'œ', 'ᠴ', 'ᡳ', '化', 'ک', 'ҡ', '한', '국', '어', 'ィ', '語', '丘', 'ǒ', 'ż', 'ă', 'ệ', '国', '國', '公', '司', '网', '络', '天', '区', 'ध', 'چ', 'ۋ', 'ې', 'ʒ', 'ۇ', 'प', 'ђ', 'ћ', 'ך', 'ῶ', 'ӧ', 'ٱ', 'ҥ', 'ӱ', 'र', 'շ', 'პ', 'ǧ', 'ܘ', 'ܦ', 'ܐ', 'ܗ', 'ܓ', 'ἐ', 'ҹ', 'ǝ', 'ḫ', 'य', 'җ', 'ם', '沙', '征', '雪', '答', '李', '淑', '一', '咏', '梅', 'ĉ', 'ĝ', 'ĥ', 'ĵ', 'ŝ', '睦', '月', 'ⵟ', 'ⵎ', 'ⵖ', 'ⴼ', 'ⵏ', 'ⵉ', 'ﻫ', 'ﺎ', '金', '清', '北', '京', '津', '上', '海', '重', '庆', '香', '港', '澳', '門', '浦', '东', '新', '民', '币', '教', 'ὶ', 'פ', 'ღ', 'ӟ', 'ὸ', 'փ', '단', 'օ', 'Ь', 'C', 'ὀ', 'घ', 'ম', 'ন', 'প', 'র', 'ɦ', 'ǎ', '남', '성', '연', '대', '男', '性', '連', '帶', 'ҧ', '¼', 'ὠ', 'ŏ', 'ἱ', 'ہ', 'ˌ', 'ộ', '河', '内', 'व', 'च', 'ṭ', 'ຽ', 'ຈ', 'ນ', 'ڤ', 'ຫ', 'ລ', 'ພ', 'ະ', 'ບ', 'າ', '高', '雄', '인', '천', '제', '물', '포', 'ᡤ', 'ᠠ', 'ᡵ', '迪', 'ʤ', 'ʈ', 'ן', '위', '키', '백', '과', 'ʻ', 'ウ', 'キ', 'ペ', 'デ', 'ア', '日', '本', '版', 'ɨ', '邦', '桑', '仲', '尼', 'ʲ', 'ʾ', 'ɾ', 'ɫ', 'ę', '조', '선', '말', 'ế', 'ữ', '越', 'ų', '佛', 'ٴ', 'ǩ', 'ۀ', 'ҷ', 'ە', 'भ', 'ष', 'ח', 'ἶ', 'ώ', '無', '產', '階', '級', '文', '大', '革', '命', 'ῥ', 'ז', '腹', '切', 'ӥ', 'ཚ', 'ང', 'ས', 'པ', 'և', 'წ', 'ֆ', 'ט', 'צ', 'ґ', 'ڭ', 'گ', 'ﭺ', 'پ', 'ژ', 'ʙ', 'ѳ', 'ѵ', 'ӓ', 'ҙ', '西', '暦', '기', 'ई', '藏', '族', '自', '治', '龍', 'ѣ', 'ﬁ', 'श', 'ण', 'ṇ', 'ჭ', 'ծ', 'ფ', 'է', 'ῦ', 'ť', 'ů', 'Ъ', '–', '+', '×', '=', '٦', 'Щ', '@', 'ą', 'ἔ', 'ὑ', 'ἡ', 'ἰ', 'ὐ', '鰲', '鼇', '鳌', 'り', 'ճ', '円', '圓', '방', '탄', '소', '년', '道', '四', '川', '省', '阿', '坝', '州', '竜', '용', 'ὁ', 'ῖ', 'ჟ', 'ὖ', 'ग', 'ѝ', 'ӈ', '山', '¾']\n"
     ]
    }
   ],
   "source": [
    "corpus_path = 'corpus_ce.txt'\n",
    "with open(corpus_path) as f:\n",
    "    text = f.read()\n",
    "\n",
    "def text_to_seq(text_sample):\n",
    "    char_counts = Counter(text_sample)\n",
    "    char_counts = sorted(char_counts.items(), key = lambda x: x[1], reverse=True)\n",
    " \n",
    "    sorted_chars = [char for char, _ in char_counts]\n",
    "    print(sorted_chars)\n",
    "    char_to_idx = {char: index for index, char in enumerate(sorted_chars)}\n",
    "    idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "    sequence = np.array([char_to_idx[char] for char in text_sample])\n",
    "    \n",
    "    return sequence, char_to_idx, idx_to_char\n",
    " \n",
    "sequence, char_to_idx, idx_to_char = text_to_seq(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T22:11:07.051897Z",
     "start_time": "2023-05-17T22:11:07.048136Z"
    },
    "id": "WbP6mNQd25Gs"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def get_batch(sequence):\n",
    "    trains = []\n",
    "    targets = []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        batch_start = np.random.randint(0, len(sequence) - SEQ_LEN)\n",
    "        chunk = sequence[batch_start: batch_start + SEQ_LEN]\n",
    "        train = torch.LongTensor(chunk[:-1]).view(-1, 1)\n",
    "        target = torch.LongTensor(chunk[1:]).view(-1, 1)\n",
    "        trains.append(train)\n",
    "        targets.append(target)\n",
    "    return torch.stack(trains, dim=0), torch.stack(targets, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T22:11:07.057624Z",
     "start_time": "2023-05-17T22:11:07.053264Z"
    },
    "id": "5Sgommwm25Gs"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
    "    hidden = model.init_hidden()\n",
    "    idx_input = [char_to_idx[char] for char in start_text]\n",
    "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
    "    predicted_text = start_text\n",
    "    \n",
    "    _, hidden = model(train, hidden)\n",
    "        \n",
    "    inp = train[-1].view(-1, 1, 1)\n",
    "    \n",
    "    for i in range(prediction_len):\n",
    "        output, hidden = model(inp.to(device), hidden)\n",
    "        output_logits = output.cpu().data.view(-1)\n",
    "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n",
    "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
    "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
    "        predicted_char = idx_to_char[top_index]\n",
    "        predicted_text += predicted_char\n",
    "    \n",
    "    return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T22:11:07.069119Z",
     "start_time": "2023-05-17T22:11:07.061561Z"
    },
    "id": "NUeLbv2625Gt"
   },
   "outputs": [],
   "source": [
    "class TextRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n",
    "        super(TextRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.input_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.encoder(x).squeeze(2)\n",
    "        out, (ht1, ct1) = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        x = self.fc(out)\n",
    "        return x, (ht1, ct1)\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n",
    "               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-17T22:10:53.464Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZh3XgJ025Gt",
    "outputId": "25330e35-aaed-4928-a785-1d2df87cd2e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.414594569206238\n",
      " нала р наш  ланаь налакада нахе икаката  каха каша  лай на нена  а ьалах лид й ни ра  ас г ран нанон ланана нан кака канараб  шан нан налана нк нан  н  й р камарил  хан кала каг к  ка  кана н танинак \n",
      "Loss: 2.945315942764282\n",
      " сера сара басха лера карка оль хе хор кков рер хела аркма кола мерор карта токар кара кар ктури конка кал хара карт кера талу ралетар кар дона как кал цатар какар катта кара халь ката калра кара кун к\n",
      "Loss: 2.803053951263428\n",
      " декал дакха кехь ха кӏала ора га келора кола лахь дахь къакха кор хар карта кара кӏалела кхакха кхахь кор куль ков къала кала кӏела лера къер калала кӏара къала дула ке лоьр ха когхоль къала карта кха\n",
      "Loss: 2.721577925682068\n",
      " далара къаь махь тӏаьр даьл дала бекхахь хьаькъ къехь мал къахь къархь сар къаьрна къахь къала мал кхьахь махь тера моли малар мар алин дора хола манха бехь мара кханан март мала халан кхалар ха тӏаьл\n",
      "Loss: 2.6382189893722536\n",
      " керт макъолла къоволор киралов карго къара корт къаьна къов морахь къов кхалла къор мар кера ков лонков йума кхора соваллан кулла ковлона кхов бора хьола къиков кхера кара ал колора дала маллан кхов к\n",
      "Loss: 2.6251076650619507\n",
      " кхехьа лорта дара хӏала дера кхалла къаьран тӏоьр ара дара деран кхара хийна архара борар доьдара сара дара дера гӏала йера растан хьала кхалла кхара дерахь йалха даман гӏала датхьа хьара дера йар алх\n",
      "Loss: 2.541777687072754\n",
      " кхал кхан кхахь кхар кхонин тӏаьна кхахь толин кхехь кха хьола кхолла кхал кхов кха къана макха кха къала кхаьн кхолла кхал кхо дехь хахь хьахь кхахь хьолан кхеха дента кхолла бола кхов гӏала хӏоха къ\n",
      "Loss: 2.554347205162048\n",
      " кхоллан ка кхолла къел кхоллан пест кхай декха докха кхоллал сив кхоллалар къоьлла даьхь къалла арахь кхалла декъ лахь хьалал соллалла саькхахь кхоллалла кхолла дехь кхаьлла сов кхолла кхолла кхуьйна \n",
      "Loss: 2.5016284656524657\n",
      " кхоллар гӏалалла мархьахь кӏошткорс доран дорт ланара марарар хьораш мартара дерг малахь карахь дерар кӏоллара кхаьр цхьаман карара кхаьр кхалла къаьрсера дерахь хьала саьра тӏоьрахьт лакъ малхалла кх\n",
      "Loss: 2.479526147842407\n",
      " болехь кхоллан деха хьала кхолла кхоллан тӏаьххьа кхоллан толонан хьола дехьа данахь дагӏ боласт малхан гӏала кхо кхахь дина хахан кхолла болан кхоллан кхолла данан кхаьх коров маркъахь дехан кхоллалл\n",
      "Loss: 2.438790636062622\n",
      " хӏухехь боьрт бер гор берахьт берахь малхахь хила болографболь хила добрахь кхоллара берара хӏакхалла болам кхоллар кхоллам хьора боран кхоллан малхалла белар хӏеху берм борахь тӏол буьлла бил берахьа\n",
      "Loss: 2.397223963737488\n",
      " кхолла малатахь тӏаьхьа кхоллан докхан кӏошттам ласт поров толастьк алукъ докхалла кхала полонан кӏоштаран боран дакъоллам тӏаьнал бер кхала кхала саст кӏошт пастонан кхоллан хьолан долам кхолла кулан\n",
      "Loss: 2.380661563873291\n",
      " кхоллар деха къаьтта дакъолгалла кхоллан дакхехь кост кхоллам карахь кхоллам кхолла дехьа тӏаьхьа арахь тӏаьхьа кхолламгӏ малхбала дакхалла дакхила дех баран дипара арс кхоллам карехь кхаллехь ковита \n",
      "Loss: 2.313883414268494\n",
      " кхолламманов карахь шера кхолладахь малха сам кхоллам кхолламехь кхалла малха кхолламма малхан кхоллам кхоллам толена наст лакъолехь хьолу бентелла болехь кхоллам декъа малха кхоллам кхолламман дохьал\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = TextRNN(input_size=len(idx_to_char), hidden_size=128, embedding_size=128, n_layers=2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience=5, \n",
    "    verbose=True, \n",
    "    factor=0.5\n",
    ")\n",
    "\n",
    "n_epochs = 10000\n",
    "loss_avg = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train, target = get_batch(sequence)\n",
    "    train = train.permute(1, 0, 2).to(device)\n",
    "    target = target.permute(1, 0, 2).to(device)\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "\n",
    "    output, hidden = model(train, hidden)\n",
    "    loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss_avg.append(loss.item())\n",
    "    if len(loss_avg) >= 50:\n",
    "        mean_loss = np.mean(loss_avg)\n",
    "        print(f'Loss: {mean_loss}')\n",
    "        scheduler.step(mean_loss)\n",
    "        loss_avg = []\n",
    "        model.eval()\n",
    "        predicted_text = evaluate(model, char_to_idx, idx_to_char)\n",
    "        print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-17T22:10:54.351Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(corpus_path) as f:\n",
    "    texts = f.readlines()\n",
    "    \n",
    "generated_texts = []\n",
    "for text in texts:\n",
    "    splitted_text = text.split()\n",
    "    generated_text = ''\n",
    "    for i, word in enumerate(splitted_text):\n",
    "        if i % 200 == 0:\n",
    "            generated_text += evaluate(model, char_to_idx, idx_to_char, temp=0.3, prediction_len=200, start_text=word)\n",
    "        \n",
    "    generated_texts.append(generated_text)\n",
    "    \n",
    "generated_path = 'generated_corpus_ce.txt'\n",
    "with open(generated_path, 'w') as f:\n",
    "    for generated_text in generated_texts:\n",
    "        f.write(generated_text + '\\n') "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
